{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long Short-Term Memory (LSTM) for rainfall-runoff modelling\n",
    "Recently, Kratzert et al. (2018a, 2018b) have shown the potential of LSTMs for rainfall-runoff modelling. Here, I'll show some example for setting up and training such a model. For single basin calibration (as done in this notebook) no GPU is required, and everything should run fine on a standard CPU (also rather slow, compared to a GPU).\n",
    "\n",
    "In this example, we use the CAMELS data set (Newman et al. 2014) that provides us with approx. 35 years of daily meteorological forcings and discharge observations from 671 basins across the contiguos USA. As input to our model we use daily precipitation sum, daily min/max temperature as well as average solar radiation and vapor pressure. \n",
    "\n",
    "\n",
    "- Kratzert, F., Klotz, D., Brenner, C., Schulz, K., and Herrnegger, M.: Rainfall–runoff modelling using Long Short-Term Memory (LSTM) networks, Hydrol. Earth Syst. Sci., 22, 6005-6022, https://doi.org/10.5194/hess-22-6005-2018, 2018a. \n",
    "\n",
    "- Kratzert F., Klotz D., Herrnegger M., Hochreiter S.: A glimpse into the Unobserved: Runoff simulation for ungauged catchments with LSTMs, Workshop on Modeling and Decision-Making in the Spatiotemporal Domain, 32nd Conference on Neural Information Processing Systems (NeuRIPS 2018), Montréal, Canada. [https://openreview.net/forum?id=Bylhm72oKX](https://openreview.net/forum?id=Bylhm72oKX), 2018b.\n",
    "\n",
    "- A. Newman; K. Sampson; M. P. Clark; A. Bock; R. J. Viger; D. Blodgett, 2014. A large-sample watershed-scale hydrometeorological dataset for the contiguous USA. Boulder, CO: UCAR/NCAR. https://dx.doi.org/10.5065/D6MW2F4D\n",
    "\n",
    "Date: 29.05.2019<br/>\n",
    "Created by: Frederik Kratzert (kratzert@ml.jku.at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List\n",
    "\n",
    "# import gcsfs\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import njit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import tqdm\n",
    "\n",
    "# Globals\n",
    "# FILE_SYSTEM = gcsfs.core.GCSFileSystem()\n",
    "CAMELS_ROOT = Path(\"/home/bernhard/git/datasets_masters/camels_ch\")\n",
    "DEVICE = torch.device(\n",
    "    \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    ")  # This line checks if GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "### CAMELS specific data loader functions\n",
    "\n",
    "Next we define two functions to load the meteorological forcings and the discharge for any specific basin from the camels data set. From the header of the forcing file we also extract the catchment area, to normalize the discharge (to mm/d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4_CAMELScl_precip_cr2met</th>\n",
       "      <th>8_CAMELScl_tmin_cr2met</th>\n",
       "      <th>9_CAMELScl_tmax_cr2met</th>\n",
       "      <th>13_CAMELScl_swe</th>\n",
       "      <th>Year</th>\n",
       "      <th>Mnth</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1979-01-01</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.313204</td>\n",
       "      <td>19.104689</td>\n",
       "      <td>0</td>\n",
       "      <td>1979</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-01-02</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.548648</td>\n",
       "      <td>19.904732</td>\n",
       "      <td>0</td>\n",
       "      <td>1979</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-01-03</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.768713</td>\n",
       "      <td>22.001092</td>\n",
       "      <td>0</td>\n",
       "      <td>1979</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-01-04</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.341378</td>\n",
       "      <td>22.916019</td>\n",
       "      <td>0</td>\n",
       "      <td>1979</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-01-05</th>\n",
       "      <td>0.008332</td>\n",
       "      <td>12.375682</td>\n",
       "      <td>23.065276</td>\n",
       "      <td>0</td>\n",
       "      <td>1979</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-27</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.040704</td>\n",
       "      <td>18.019793</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-28</th>\n",
       "      <td>0.008741</td>\n",
       "      <td>10.746008</td>\n",
       "      <td>21.836417</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-29</th>\n",
       "      <td>0.024894</td>\n",
       "      <td>11.518364</td>\n",
       "      <td>20.818686</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-30</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.345369</td>\n",
       "      <td>20.461237</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-31</th>\n",
       "      <td>0.006872</td>\n",
       "      <td>8.785521</td>\n",
       "      <td>20.844411</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13880 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            4_CAMELScl_precip_cr2met  8_CAMELScl_tmin_cr2met  \\\n",
       "Date                                                           \n",
       "1979-01-01                  0.000000                8.313204   \n",
       "1979-01-02                  0.000000                9.548648   \n",
       "1979-01-03                  0.000000               11.768713   \n",
       "1979-01-04                  0.000000               13.341378   \n",
       "1979-01-05                  0.008332               12.375682   \n",
       "...                              ...                     ...   \n",
       "2016-12-27                  0.000000                4.040704   \n",
       "2016-12-28                  0.008741               10.746008   \n",
       "2016-12-29                  0.024894               11.518364   \n",
       "2016-12-30                  0.000000               10.345369   \n",
       "2016-12-31                  0.006872                8.785521   \n",
       "\n",
       "            9_CAMELScl_tmax_cr2met 13_CAMELScl_swe  Year  Mnth  Day    Hr  \n",
       "Date                                                                       \n",
       "1979-01-01               19.104689               0  1979     1    1  12.0  \n",
       "1979-01-02               19.904732               0  1979     1    2  12.0  \n",
       "1979-01-03               22.001092               0  1979     1    3  12.0  \n",
       "1979-01-04               22.916019               0  1979     1    4  12.0  \n",
       "1979-01-05               23.065276               0  1979     1    5  12.0  \n",
       "...                            ...             ...   ...   ...  ...   ...  \n",
       "2016-12-27               18.019793               0  2016    12   27  12.0  \n",
       "2016-12-28               21.836417               0  2016    12   28  12.0  \n",
       "2016-12-29               20.818686               0  2016    12   29  12.0  \n",
       "2016-12-30               20.461237               0  2016    12   30  12.0  \n",
       "2016-12-31               20.844411               0  2016    12   31  12.0  \n",
       "\n",
       "[13880 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_forcing(basin: str) -> Tuple[pd.DataFrame, int]:\n",
    "    \"\"\"Load the meteorological forcing data of a specific basin.\n",
    "\n",
    "    :param basin: 8-digit code of basin as string.\n",
    "\n",
    "    :return: pd.DataFrame containing the meteorological forcing data and the\n",
    "        area of the basin as integer.\n",
    "    \"\"\"\n",
    "    features = [\n",
    "        \"4_CAMELScl_precip_cr2met\",  # Precipitation\n",
    "        \"8_CAMELScl_tmin_cr2met\",  # Min temp\n",
    "        \"9_CAMELScl_tmax_cr2met\",  # Max temp\n",
    "        # \"11_CAMELScl_pet_8d_modis\",  # Potential evapotranspiration modis\n",
    "        \"13_CAMELScl_swe\",\n",
    "    ]\n",
    "    df_final = pd.DataFrame(columns=[\"Date\"] + features)\n",
    "    for i, feature in enumerate(features):\n",
    "        path = CAMELS_ROOT / feature / (feature + \".txt\")\n",
    "        df = pd.read_table(path)\n",
    "        # print(f\"{feature}: {len(df[basin])}\")\n",
    "        # if feature[0:2] == \"13\":\n",
    "        #    return df, 0\n",
    "        # if feature == features[-1]:\n",
    "        #    return df.dropna(), 0\n",
    "        df_final[feature] = df[basin]\n",
    "        # return df_final\n",
    "        if i == 0:\n",
    "            dates = pd.to_datetime(df[\"gauge_id\"])\n",
    "            year = []\n",
    "            day = []\n",
    "            month = []\n",
    "            hour = np.ones(len(dates)) * 12\n",
    "            for date in df[\"gauge_id\"]:\n",
    "                # print(date.split(\"-\"))\n",
    "                date_split = date.split(\"-\")\n",
    "                year.append(int(date_split[0]))\n",
    "                month.append(int(date_split[1]))\n",
    "                day.append(int(date_split[2]))\n",
    "            df_final[\"Year\"] = np.array(year)\n",
    "            df_final[\"Mnth\"] = np.array(month)\n",
    "            df_final[\"Day\"] = np.array(day)\n",
    "            df_final[\"Hr\"] = hour\n",
    "            df_final[\"Date\"] = dates\n",
    "    df_final.set_index(\"Date\", inplace=True)\n",
    "    # return df_final\n",
    "\n",
    "    # area_path = CAMELS_ROOT / \"CAMELScl_catchment_boundaries\" / \"CAMELScl_catchment_boundaries\" / \"catchments_camels_cl_v1.3.dbf\"\n",
    "    df_final[\"13_CAMELScl_swe\"].fillna(0, inplace=True)\n",
    "    area_path = (\n",
    "        CAMELS_ROOT\n",
    "        / \"CAMELScl_catchment_boundaries\"\n",
    "        / \"CAMELScl_catchment_boundaries\"\n",
    "        / \"catchments_camels_cl_v1.3.xls\"\n",
    "    )\n",
    "    df_area = pd.read_excel(area_path)\n",
    "    area = df_area[df_area[df_area.columns[0]] == int(basin)][\n",
    "        df_area.columns[-1]\n",
    "    ].to_numpy()[0]\n",
    "    return df_final, int(area * 1000 ** 2)\n",
    "\n",
    "\n",
    "def load_discharge(basin: str, area: int, dates: pd.Series) -> pd.Series:\n",
    "    \"\"\"Load the discharge time series for a specific basin.\n",
    "\n",
    "    :param basin: 8-digit code of basin as string.\n",
    "    :param area: int, area of the catchment in square meters\n",
    "\n",
    "    :return: A pd.Series containng the catchment normalized discharge.\n",
    "    \"\"\"\n",
    "\n",
    "    discharge_path = CAMELS_ROOT / \"3_CAMELScl_streamflow_mm.txt\"\n",
    "\n",
    "    df = pd.read_table(discharge_path, low_memory=False)\n",
    "    df[\"gauge_id\"] = pd.to_datetime(df[\"gauge_id\"])\n",
    "    df.set_index(\"gauge_id\", inplace=True)\n",
    "    df = df[basin].replace(\" \", np.nan)\n",
    "    df.fillna(0, inplace=True)\n",
    "    df = pd.to_numeric(df)\n",
    "    df = df[dates[0] : dates[-1]]\n",
    "    # df = df * 60 ** 2 * 24 / (area * 10 ** 6)\n",
    "    return df\n",
    "\n",
    "\n",
    "basin = \"5710001\"\n",
    "forcing, area = load_forcing(basin)\n",
    "load_discharge(basin, area, forcing.index.to_series())\n",
    "forcing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data reshaping for LSTM training\n",
    "Next we need another utility function to reshape the data into an appropriate format for training LSTMs. These recurrent neural networks expect sequential input of the shape `(sequence length, number of features)`. We train our network to predict a single day of discharge from *n* days of precendent meteorological observations. For example, lets assume that _n_ = 365, then a single training sample should be of shape `(365, number of features)`, and since we use 5 input features the shape is `(365, 5)`.\n",
    "\n",
    "However, when loaded from the files the entire data is stored in a matrix, where the number of rows correspond to the total number of days in the training set and the number of columns to the features. Thus we need to slide over this matrix and cut out small samples appropriate to our LSTM setting. To speed things up, we make use of the awesome Numba library here (the little @njit decorator JIT-compiles this function and dramatically increases the speed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def reshape_data(\n",
    "    x: np.ndarray, y: np.ndarray, seq_length: int\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Reshape matrix data into sample shape for LSTM training.\n",
    "\n",
    "    :param x: Matrix containing input features column wise and time steps row wise\n",
    "    :param y: Matrix containing the output feature.\n",
    "    :param seq_length: Length of look back days for one day of prediction\n",
    "\n",
    "    :return: Two np.ndarrays, the first of shape (samples, length of sequence,\n",
    "        number of features), containing the input data for the LSTM. The second\n",
    "        of shape (samples, 1) containing the expected output for each input\n",
    "        sample.\n",
    "    \"\"\"\n",
    "    num_samples, num_features = x.shape\n",
    "\n",
    "    x_new = np.zeros((num_samples - seq_length + 1, seq_length, num_features))\n",
    "    y_new = np.zeros((num_samples - seq_length + 1, 1))\n",
    "\n",
    "    for i in range(0, x_new.shape[0]):\n",
    "        x_new[i, :, :num_features] = x[i : i + seq_length, :]\n",
    "        y_new[i, :] = y[i + seq_length - 1, 0]\n",
    "\n",
    "    return x_new, y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch data set\n",
    "Now we wrap everything into a PyTorch Dataset. These are specific classes that can be used by PyTorchs DataLoader class for generating mini-batches (and do this in parallel in multiple threads). Such a data set class has to inherit from the PyTorch Dataset class and three functions have to be implemented\n",
    "\n",
    "1. __init__(): The object initializing function.\n",
    "2. __len__(): This function has to return the number of samples in the data set.\n",
    "3. __getitem__(i): A function that returns sample `i` of the data set (sample + target value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CamelsTXT(Dataset):\n",
    "    \"\"\"Torch Dataset for basic use of data from the CAMELS data set.\n",
    "\n",
    "    This data set provides meteorological observations and discharge of a given\n",
    "    basin from the CAMELS data set.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        basin: str,\n",
    "        seq_length: int = 365,\n",
    "        period: str = None,\n",
    "        dates: List = None,\n",
    "        means: pd.Series = None,\n",
    "        stds: pd.Series = None,\n",
    "    ):\n",
    "        \"\"\"Initialize Dataset containing the data of a single basin.\n",
    "\n",
    "        :param basin: 8-digit code of basin as string.\n",
    "        :param seq_length: (optional) Length of the time window of\n",
    "            meteorological input provided for one time step of prediction.\n",
    "        :param period: (optional) One of ['train', 'eval']. None loads the\n",
    "            entire time series.\n",
    "        :param dates: (optional) List of pd.DateTimes of the start and end date\n",
    "            of the discharge period that is used.\n",
    "        :param means: (optional) Means of input and output features derived from\n",
    "            the training period. Has to be provided for 'eval' period. Can be\n",
    "            retrieved if calling .get_means() on the data set.\n",
    "        :param stds: (optional) Stds of input and output features derived from\n",
    "            the training period. Has to be provided for 'eval' period. Can be\n",
    "            retrieved if calling .get_stds() on the data set.\n",
    "        \"\"\"\n",
    "        self.basin = basin\n",
    "        self.seq_length = seq_length\n",
    "        self.period = period\n",
    "        self.dates = dates\n",
    "        self.means = means\n",
    "        self.stds = stds\n",
    "\n",
    "        # load data into memory\n",
    "        self.x, self.y = self._load_data()\n",
    "\n",
    "        # store number of samples as class attribute\n",
    "        self.num_samples = self.x.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "    def _load_data(self):\n",
    "        \"\"\"Load input and output data from text files.\"\"\"\n",
    "        df, area = load_forcing(self.basin)\n",
    "        df[\"5710001\"] = load_discharge(self.basin, area, df.index.to_series())\n",
    "        # df.dropna(inplace=True)\n",
    "        # print(df)\n",
    "\n",
    "        if self.dates is not None:\n",
    "            # If meteorological observations exist before start date\n",
    "            # use these as well. Similiar to hydrological warmup period.\n",
    "            if self.dates[0] - pd.DateOffset(days=self.seq_length) > df.index[0]:\n",
    "                start_date = self.dates[0] - pd.DateOffset(days=self.seq_length)\n",
    "            else:\n",
    "                start_date = self.dates[0]\n",
    "            df = df[start_date : self.dates[1]]\n",
    "            print(df)\n",
    "\n",
    "        # if training period store means and stds\n",
    "        if self.period == \"train\":\n",
    "            self.means = df.mean()\n",
    "            self.stds = df.std()\n",
    "        features = [\n",
    "            \"4_CAMELScl_precip_cr2met\",  # Precipitation\n",
    "            \"8_CAMELScl_tmin_cr2met\",  # Min temp\n",
    "            \"9_CAMELScl_tmax_cr2met\",  # Max temp\n",
    "            \"13_CAMELScl_swe\",\n",
    "        ]\n",
    "        # extract input and output features from DataFrame\n",
    "        x = np.array(\n",
    "            [\n",
    "                df[\"4_CAMELScl_precip_cr2met\"].values,\n",
    "                df[\"9_CAMELScl_tmax_cr2met\"].values,\n",
    "                df[\"8_CAMELScl_tmin_cr2met\"].values,\n",
    "                df[\"13_CAMELScl_swe\"].values,\n",
    "            ]\n",
    "        ).T\n",
    "        y = np.array([df[\"5710001\"].values]).T\n",
    "\n",
    "        # normalize data, reshape for LSTM training and remove invalid samples\n",
    "        x = self._local_normalization(x, variable=\"inputs\")\n",
    "        x, y = reshape_data(x, y, self.seq_length)\n",
    "\n",
    "        if self.period == \"train\":\n",
    "            # Delete all samples, where discharge is NaN\n",
    "            if np.sum(np.isnan(y)) > 0:\n",
    "                print(f\"Deleted some records because of NaNs {self.basin}\")\n",
    "                x = np.delete(x, np.argwhere(np.isnan(y)), axis=0)\n",
    "                y = np.delete(y, np.argwhere(np.isnan(y)), axis=0)\n",
    "\n",
    "            # Deletes all records, where no discharge was measured (-999)\n",
    "            x = np.delete(x, np.argwhere(y < 0)[:, 0], axis=0)\n",
    "            y = np.delete(y, np.argwhere(y < 0)[:, 0], axis=0)\n",
    "\n",
    "            # normalize discharge\n",
    "            y = self._local_normalization(y, variable=\"output\")\n",
    "\n",
    "        # convert arrays to torch tensors\n",
    "        x = torch.from_numpy(x.astype(np.float32))\n",
    "        y = torch.from_numpy(y.astype(np.float32))\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def _local_normalization(self, feature: np.ndarray, variable: str) -> np.ndarray:\n",
    "        \"\"\"Normalize input/output features with local mean/std.\n",
    "\n",
    "        :param feature: Numpy array containing the feature(s) as matrix.\n",
    "        :param variable: Either 'inputs' or 'output' showing which feature will\n",
    "            be normalized\n",
    "        :return: array containing the normalized feature\n",
    "        \"\"\"\n",
    "        features = [\n",
    "            \"4_CAMELScl_precip_cr2met\",  # Precipitation\n",
    "            \"8_CAMELScl_tmin_cr2met\",  # Min temp\n",
    "            \"9_CAMELScl_tmax_cr2met\",  # Max temp\n",
    "            # \"11_CAMELScl_pet_8d_modis\",  # Potential evapotranspiration modis\n",
    "            \"13_CAMELScl_swe\",\n",
    "        ]\n",
    "        if variable == \"inputs\":\n",
    "            print(self.means)\n",
    "            means = np.array(\n",
    "                [\n",
    "                    self.means[\"4_CAMELScl_precip_cr2met\"],\n",
    "                    self.means[\"9_CAMELScl_tmax_cr2met\"],\n",
    "                    self.means[\"8_CAMELScl_tmin_cr2met\"],\n",
    "                    self.means[\"13_CAMELScl_swe\"],\n",
    "                ]\n",
    "            )\n",
    "            stds = np.array(\n",
    "                [\n",
    "                    self.stds[\"4_CAMELScl_precip_cr2met\"],\n",
    "                    self.stds[\"9_CAMELScl_tmax_cr2met\"],\n",
    "                    self.stds[\"8_CAMELScl_tmin_cr2met\"],\n",
    "                    self.stds[\"13_CAMELScl_swe\"],\n",
    "                ]\n",
    "            )\n",
    "            feature = (feature - means) / stds\n",
    "        elif variable == \"output\":\n",
    "            feature = (feature - self.means[\"5710001\"]) / self.stds[\"5710001\"]\n",
    "        else:\n",
    "            raise RuntimeError(f\"Unknown variable type {variable}\")\n",
    "\n",
    "        return feature\n",
    "\n",
    "    def local_rescale(self, feature: np.ndarray, variable: str) -> np.ndarray:\n",
    "        \"\"\"Rescale input/output features with local mean/std.\n",
    "\n",
    "        :param feature: Numpy array containing the feature(s) as matrix.\n",
    "        :param variable: Either 'inputs' or 'output' showing which feature will\n",
    "            be normalized\n",
    "        :return: array containing the normalized feature\n",
    "        \"\"\"\n",
    "        if variable == \"inputs\":\n",
    "            means = np.array(\n",
    "                [\n",
    "                    self.means[\"4_CAMELScl_precip_cr2met\"],\n",
    "                    self.means[\"9_CAMELScl_tmax_cr2met\"],\n",
    "                    self.means[\"8_CAMELScl_tmin_cr2met\"],\n",
    "                    self.means[\"13_CAMELScl_swe\"],\n",
    "                ]\n",
    "            )\n",
    "            stds = np.array(\n",
    "                [\n",
    "                    self.stds[\"4_CAMELScl_precip_cr2met\"],\n",
    "                    self.stds[\"9_CAMELScl_tmax_cr2met\"],\n",
    "                    self.stds[\"8_CAMELScl_tmin_cr2met\"],\n",
    "                    self.stds[\"13_CAMELScl_swe\"],\n",
    "                ]\n",
    "            )\n",
    "            feature = feature * stds + means\n",
    "        elif variable == \"output\":\n",
    "            feature = feature * self.stds[\"5710001\"] + self.means[\"5710001\"]\n",
    "        else:\n",
    "            raise RuntimeError(f\"Unknown variable type {variable}\")\n",
    "\n",
    "        return feature\n",
    "\n",
    "    def get_means(self):\n",
    "        return self.means\n",
    "\n",
    "    def get_stds(self):\n",
    "        return self.stds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build LSTM model\n",
    "\n",
    "Here we implement a single layer LSTM with optional dropout in the final fully connected layer. Using PyTorch, we need to inherit from the `nn.Module` class and implement the `__init__()`, as well as a `forward()` function. To make things easy, we make use of the standard LSTM layer included in the PyTorch library.\n",
    "\n",
    "The forward function implements the entire forward pass through the network, while the backward pass, used for updating the weights during training, is automatically derived from PyTorch autograd functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \"\"\"Implementation of a single layer LSTM network\"\"\"\n",
    "\n",
    "    def __init__(self, hidden_size: int, dropout_rate: float = 0.0):\n",
    "        \"\"\"Initialize model\n",
    "\n",
    "        :param hidden_size: Number of hidden units/LSTM cells\n",
    "        :param dropout_rate: Dropout rate of the last fully connected\n",
    "            layer. Default 0.0\n",
    "        \"\"\"\n",
    "        super(Model, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        # create required layer\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=4,\n",
    "            hidden_size=self.hidden_size,\n",
    "            num_layers=1,\n",
    "            bias=True,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.dropout = nn.Dropout(p=self.dropout_rate)\n",
    "        self.fc = nn.Linear(in_features=self.hidden_size, out_features=1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass through the Network.\n",
    "\n",
    "        :param x: Tensor of shape [batch size, seq length, num features]\n",
    "            containing the input data for the LSTM network.\n",
    "\n",
    "        :return: Tensor containing the network predictions\n",
    "        \"\"\"\n",
    "        output, (h_n, c_n) = self.lstm(x)\n",
    "\n",
    "        # perform prediction only at the end of the input sequence\n",
    "        pred = self.fc(self.dropout(h_n[-1, :, :]))\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train utilities\n",
    "\n",
    "Next we are implementing two functions for training and evaluating the model.\n",
    "\n",
    "- `train_epoch()`: This function iterates one time over the entire training data set (called one epoch) and updates the weights of the network to minimize the loss function (we use the mean squared error here).\n",
    "- `eval_model()`: To this function evaluates a data set and returns the predictions, as well as observations.\n",
    "\n",
    "Furthermore we implement a function `calc_nse()` to calculate the Nash-Sutcliffe-Efficiency for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, loader, loss_func, epoch):\n",
    "    \"\"\"Train model for a single epoch.\n",
    "\n",
    "    :param model: A torch.nn.Module implementing the LSTM model\n",
    "    :param optimizer: One of PyTorchs optimizer classes.\n",
    "    :param loader: A PyTorch DataLoader, providing the trainings\n",
    "        data in mini batches.\n",
    "    :param loss_func: The loss function to minimize.\n",
    "    :param epoch: The current epoch (int) used for the progress bar\n",
    "    \"\"\"\n",
    "    # set model to train mode (important for dropout)\n",
    "    model.train()\n",
    "    pbar = tqdm.tqdm_notebook(loader)\n",
    "    pbar.set_description(f\"Epoch {epoch}\")\n",
    "    # request mini-batch of data from the loader\n",
    "    for xs, ys in pbar:\n",
    "        # delete previously stored gradients from the model\n",
    "        optimizer.zero_grad()\n",
    "        # push data to GPU (if available)\n",
    "        xs, ys = xs.to(DEVICE), ys.to(DEVICE)\n",
    "        # get model predictions\n",
    "        y_hat = model(xs)\n",
    "        # calculate loss\n",
    "        loss = loss_func(y_hat, ys)\n",
    "        # calculate gradients\n",
    "        loss.backward()\n",
    "        # update the weights\n",
    "        optimizer.step()\n",
    "        # write current loss in the progress bar\n",
    "        pbar.set_postfix_str(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "\n",
    "def eval_model(model, loader) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Evaluate the model.\n",
    "\n",
    "    :param model: A torch.nn.Module implementing the LSTM model\n",
    "    :param loader: A PyTorch DataLoader, providing the data.\n",
    "\n",
    "    :return: Two torch Tensors, containing the observations and\n",
    "        model predictions\n",
    "    \"\"\"\n",
    "    # set model to eval mode (important for dropout)\n",
    "    model.eval()\n",
    "    obs = []\n",
    "    preds = []\n",
    "    # in inference mode, we don't need to store intermediate steps for\n",
    "    # backprob\n",
    "    with torch.no_grad():\n",
    "        # request mini-batch of data from the loader\n",
    "        for xs, ys in loader:\n",
    "            # push data to GPU (if available)\n",
    "            xs = xs.to(DEVICE)\n",
    "            # get model predictions\n",
    "            y_hat = model(xs)\n",
    "            obs.append(ys)\n",
    "            preds.append(y_hat)\n",
    "\n",
    "    return torch.cat(obs), torch.cat(preds)\n",
    "\n",
    "\n",
    "def calc_nse(obs: np.array, sim: np.array) -> float:\n",
    "    \"\"\"Calculate Nash-Sutcliff-Efficiency.\n",
    "\n",
    "    :param obs: Array containing the observations\n",
    "    :param sim: Array containing the simulations\n",
    "    :return: NSE value.\n",
    "    \"\"\"\n",
    "    # print(sim)\n",
    "    # only consider time steps, where observations are available\n",
    "    sim = np.delete(sim, np.argwhere(obs < 0), axis=0)\n",
    "    obs = np.delete(obs, np.argwhere(obs < 0), axis=0)\n",
    "\n",
    "    # check for NaNs in observations\n",
    "    sim = np.delete(sim, np.argwhere(np.isnan(obs)), axis=0)\n",
    "    obs = np.delete(obs, np.argwhere(np.isnan(obs)), axis=0)\n",
    "\n",
    "    denominator = np.sum((obs - np.mean(obs)) ** 2)\n",
    "    numerator = np.sum((sim - obs) ** 2)\n",
    "    nse_val = 1 - numerator / denominator\n",
    "\n",
    "    return nse_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare everything for training\n",
    "\n",
    "Now that we have everything needed, we have to do the following steps:\n",
    "\n",
    "- Specify a training, as well independent validation and test periods. For each of the three create a PyTorch data set and with these data sets PyTorch DataLoader. These DataLoader put single samples together to mini-batches that we use to train the network.\n",
    "- Initialize the model\n",
    "- Create a optimizer\n",
    "- Define the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            4_CAMELScl_precip_cr2met  8_CAMELScl_tmin_cr2met  \\\n",
      "Date                                                           \n",
      "1979-10-02                  0.013633               -7.987919   \n",
      "1979-10-03                  0.067707               -5.738807   \n",
      "1979-10-04                  0.000000               -5.950103   \n",
      "1979-10-05                  0.000000               -6.796480   \n",
      "1979-10-06                  0.000000               -4.727923   \n",
      "...                              ...                     ...   \n",
      "1995-09-26                  1.302073               -3.056221   \n",
      "1995-09-27                  1.976769               -2.392576   \n",
      "1995-09-28                  0.012593               -6.653489   \n",
      "1995-09-29                  0.000000               -3.575155   \n",
      "1995-09-30                  0.003895                1.530757   \n",
      "\n",
      "            9_CAMELScl_tmax_cr2met   13_CAMELScl_swe  Year  Mnth  Day    Hr  \\\n",
      "Date                                                                          \n",
      "1979-10-02                4.411733  287.241404527573  1979    10    2  12.0   \n",
      "1979-10-03                6.024469   282.41652698062  1979    10    3  12.0   \n",
      "1979-10-04                5.368725  275.613230608163  1979    10    4  12.0   \n",
      "1979-10-05                5.993501   268.11392411142  1979    10    5  12.0   \n",
      "1979-10-06                8.944842  260.828741584795  1979    10    6  12.0   \n",
      "...                            ...               ...   ...   ...  ...   ...   \n",
      "1995-09-26                4.901443   196.00276681455  1995     9   26  12.0   \n",
      "1995-09-27                3.666547  192.201856919938  1995     9   27  12.0   \n",
      "1995-09-28                3.158097  187.521021183226  1995     9   28  12.0   \n",
      "1995-09-29                7.877469  181.410757238949  1995     9   29  12.0   \n",
      "1995-09-30                9.153519  175.316917840116  1995     9   30  12.0   \n",
      "\n",
      "             5710001  \n",
      "Date                  \n",
      "1979-10-02  0.976655  \n",
      "1979-10-03  0.896309  \n",
      "1979-10-04  0.949873  \n",
      "1979-10-05  0.928447  \n",
      "1979-10-06  0.983797  \n",
      "...              ...  \n",
      "1995-09-26  1.237335  \n",
      "1995-09-27  1.255189  \n",
      "1995-09-28  1.224836  \n",
      "1995-09-29  1.246262  \n",
      "1995-09-30  1.380173  \n",
      "\n",
      "[5843 rows x 9 columns]\n",
      "4_CAMELScl_precip_cr2met       2.179600\n",
      "8_CAMELScl_tmin_cr2met         2.606525\n",
      "9_CAMELScl_tmax_cr2met        12.267894\n",
      "Year                        1987.248502\n",
      "Mnth                           6.522334\n",
      "Day                           15.732158\n",
      "Hr                            12.000000\n",
      "5710001                        2.181986\n",
      "dtype: float64\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'13_CAMELScl_swe'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.local/share/virtualenvs/pangeo_lstm_example_camels_cl-aGj-LBsu/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2888\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2889\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2890\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '13_CAMELScl_swe'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-a3e588c07a87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mstart_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"1980-10-01\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"%Y-%m-%d\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mend_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"1995-09-30\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"%Y-%m-%d\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m ds_train = CamelsTXT(\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mbasin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_date\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-14-098212050f0f>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, basin, seq_length, period, dates, means, stds)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# load data into memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# store number of samples as class attribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-098212050f0f>\u001b[0m in \u001b[0;36m_load_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;31m# normalize data, reshape for LSTM training and remove invalid samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_local_normalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"inputs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreshape_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-098212050f0f>\u001b[0m in \u001b[0;36m_local_normalization\u001b[0;34m(self, feature, variable)\u001b[0m\n\u001b[1;32m    134\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"9_CAMELScl_tmax_cr2met\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"8_CAMELScl_tmin_cr2met\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"13_CAMELScl_swe\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m                 ]\n\u001b[1;32m    138\u001b[0m             )\n",
      "\u001b[0;32m~/.local/share/virtualenvs/pangeo_lstm_example_camels_cl-aGj-LBsu/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m         if (\n",
      "\u001b[0;32m~/.local/share/virtualenvs/pangeo_lstm_example_camels_cl-aGj-LBsu/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 991\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    992\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/pangeo_lstm_example_camels_cl-aGj-LBsu/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2890\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2891\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2893\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '13_CAMELScl_swe'"
     ]
    }
   ],
   "source": [
    "basin = (\n",
    "    \"5710001\"  # can be changed to any 8-digit basin id contained in the CAMELS data set\n",
    ")\n",
    "hidden_size = 10  # Number of LSTM cells\n",
    "dropout_rate = 0.0  # Dropout rate of the final fully connected Layer [0.0, 1.0]\n",
    "learning_rate = 1e-3  # Learning rate used to update the weights\n",
    "sequence_length = 365  # Length of the meteorological record provided to the network\n",
    "\n",
    "##############\n",
    "# Data set up#\n",
    "##############\n",
    "\n",
    "# Training data\n",
    "start_date = pd.to_datetime(\"1980-10-01\", format=\"%Y-%m-%d\")\n",
    "end_date = pd.to_datetime(\"1995-09-30\", format=\"%Y-%m-%d\")\n",
    "ds_train = CamelsTXT(\n",
    "    basin, seq_length=sequence_length, period=\"train\", dates=[start_date, end_date]\n",
    ")\n",
    "tr_loader = DataLoader(ds_train, batch_size=256, shuffle=True)\n",
    "\n",
    "# Validation data. We use the feature means/stds of the training period for normalization\n",
    "means = ds_train.get_means()\n",
    "stds = ds_train.get_stds()\n",
    "start_date = pd.to_datetime(\"1995-10-01\", format=\"%Y-%m-%d\")\n",
    "end_date = pd.to_datetime(\"2000-09-30\", format=\"%Y-%m-%d\")\n",
    "ds_val = CamelsTXT(\n",
    "    basin,\n",
    "    seq_length=sequence_length,\n",
    "    period=\"eval\",\n",
    "    dates=[start_date, end_date],\n",
    "    means=means,\n",
    "    stds=stds,\n",
    ")\n",
    "val_loader = DataLoader(ds_val, batch_size=2048, shuffle=False)\n",
    "\n",
    "# Test data. We use the feature means/stds of the training period for normalization\n",
    "start_date = pd.to_datetime(\"2000-10-01\", format=\"%Y-%m-%d\")\n",
    "end_date = pd.to_datetime(\"2010-09-30\", format=\"%Y-%m-%d\")\n",
    "ds_test = CamelsTXT(\n",
    "    basin,\n",
    "    seq_length=sequence_length,\n",
    "    period=\"eval\",\n",
    "    dates=[start_date, end_date],\n",
    "    means=means,\n",
    "    stds=stds,\n",
    ")\n",
    "test_loader = DataLoader(ds_test, batch_size=2048, shuffle=False)\n",
    "\n",
    "\n",
    "#########################\n",
    "# Model, Optimizer, Loss#\n",
    "#########################\n",
    "\n",
    "# Here we create our model, feel free\n",
    "model = Model(hidden_size=hidden_size, dropout_rate=dropout_rate).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "Now we gonna train the model for some number of epochs. After each epoch we evaluate the model on the validation period and print out the NSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20  # Number of training epochs\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    train_epoch(model, optimizer, tr_loader, loss_func, i + 1)\n",
    "    obs, preds = eval_model(model, val_loader)\n",
    "    preds = ds_val.local_rescale(preds.cpu().numpy(), variable=\"output\")\n",
    "    nse = calc_nse(obs.cpu().numpy(), preds)\n",
    "    tqdm.tqdm.write(f\"Validation NSE: {nse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate independent test set\n",
    "Finally, we can can evaluate our model on the unseen test data, calculate the NSE and plot some observations vs predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "obs, preds = eval_model(model, test_loader)\n",
    "preds = ds_val.local_rescale(preds.cpu().numpy(), variable=\"output\")\n",
    "obs = obs.cpu().numpy()\n",
    "nse = calc_nse(obs, preds)\n",
    "\n",
    "# Plot results\n",
    "start_date = ds_test.dates[0]\n",
    "end_date = ds_test.dates[1] + pd.DateOffset(days=1)\n",
    "date_range = pd.date_range(start_date, end_date)\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "ax.plot(date_range, obs, label=\"observation\")\n",
    "ax.plot(date_range, preds, label=\"prediction\")\n",
    "ax.legend()\n",
    "ax.set_title(f\"Basin {basin} - Test set NSE: {nse:.3f}\")\n",
    "ax.xaxis.set_tick_params(rotation=90)\n",
    "ax.set_xlabel(\"Date\")\n",
    "_ = ax.set_ylabel(\"Discharge (mm/d)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, you have trained a LSTM. Although results for single basin calibration might not look superior to traditional hydrological models don't forget that this model had to learn every hydrological process from scratch. Also note that, due to computational contraints of the Pangeo servers, we trained very small LSTM networks. However, while getting the overall dynamics farely well, we can see that the LSTM (as most hydrological models) has problems with peak flows and is mostly underestimating them. \n",
    "\n",
    "I hope you are able with the code provided in this notebook to try LSTMs on your own data/problems. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
